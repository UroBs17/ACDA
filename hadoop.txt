haddop-namenode:ec2-3-80-180-13.compute-1.amazonaws.com
hadoop-datanode1:ec2-54-173-152-183.compute-1.amazonaws.com
hadoop-datanode2:ec2-100-26-183-255.compute-1.amazonaws.com
hadoop-datanode3:ec2-3-88-45-201.compute-1.amazonaws.com

mkdir server
cd server
wget https://downloads.apache.org/hadoop/common/hadoop-2.9.2/hadoop-2.9.2.tar.gz
tar xvzf hadoop-2.9.2.tar.gz

nano ~/server/hadoop-2.9.2/etc/hadoop/hadoop-env.sh

1.
nano ~/server/hadoop-2.9.2/etc/hadoop/core-site.xml

<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>ec2-3-80-180-13.compute-1.amazonaws.com:9000</value>
  </property>
</configuration>

2.
ls -la /usr/local/hadoop/hdfs/
tiene que estar data a nombre de ubuntu
3.
nnode>ssh-keygen
cat .ssh/id_rsa.pub
echo "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCvXT4V8SVTshCVfO8RB1J9BhVEzfBPgrsd8PYqAEueDKN9j/cNOJ2FBjUD/Ee/R7tS7cJVtg5Z7dd6luWTafycu+ifs5SoolHhTm4IhSA8bcUtpqOv0OIUtrd42OF/APj4ZV7hmVvw73YE++GZk9lGl/54FyjwdqL7bK2wJNqwT3XRyVw4mLO6lmDZX39oC+PSdglc1xEFttDolmlYtvodavPhgrglFwRVRxy9TEk9HLnVZclXDPq+AEZ09vPwR+tZ0+VRE/sCLFmHgOev4y1PYNA4ClQ//QK2RG68qKBo4VZ96y88OfmHvQ/9ZzwGG8Ad2b3PlNsxGObPa1RGaFlF ubuntu@ip-172-31-83-21">> authorized_keys

4.
/////
Host namenode
  HostName ec2-3-80-180-13.compute-1.amazonaws.com
  User ubuntu
  IdentityFile ~/.ssh/id_rsa

Host datanode1
  HostName ec2-54-173-152-183.compute-1.amazonaws.com
  User ubuntu
  IdentityFile ~/.ssh/id_rsa

Host datanode2
  HostName ec2-100-26-183-255.compute-1.amazonaws.com
  User ubuntu
  IdentityFile ~/.ssh/id_rsa

Host datanode3
  HostName ec2-3-88-45-201.compute-1.amazonaws.com
  User ubuntu
  IdentityFile ~/.ssh/id_rsa
///
 
nano ~/server/hadoop-2.9.2/etc/hadoop/hdfs-site.xml 

<configuration>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>ec2-3-80-180-13.compute-1.amazonaws.com:54311</value>
  </property>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>


<configuration>

  <!-- Site specific YARN configuration properties -->
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>ec2-3-80-180-13.compute-1.amazonaws.com</value>
  </property>

</configuration>


  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///usr/local/hadoop/hdfs/data</value>
  </property>